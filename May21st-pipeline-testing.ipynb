{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import cv2\n",
    "import pickle\n",
    "from skimage import measure, segmentation, feature\n",
    "from vis_utils import load_volume, VolumeVisualizer, ColorMapVisualizer\n",
    "from scipy.ndimage import zoom\n",
    "from skimage.morphology import skeletonize, skeletonize_3d, binary_dilation\n",
    "from skimage import filters, morphology\n",
    "from scipy.ndimage.filters import convolve, correlate\n",
    "from scipy import signal\n",
    "from skimage.filters import frangi, sato\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "TREE_NAME = 'P11'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'P01': './data/P01/P01_60um_1612x623x1108.raw',\n",
       " 'P04': './data/P04/P04_60um_1273x466x1045.raw',\n",
       " 'P11': './data/P11/P11_60um_1735x595x1150.raw',\n",
       " 'P12': './data/P12/P12_60um_1333x443x864.raw'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source_dir = './data/'\n",
    "files = {path.split('/')[2]: path for path in sorted(glob.glob(source_dir + '*/*.raw'))}\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(575, 298, 868)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scales = {\n",
    "    'P04': 0.5,\n",
    "    'P11': 0.5,\n",
    "    'P12': 0.5,\n",
    "}\n",
    "\n",
    "volume = load_volume(files[TREE_NAME], scale=scales[TREE_NAME])\n",
    "volume.shape\n",
    "# VolumeVisualizer(volume, binary=False).visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds = {\n",
    "    'P04': 30,\n",
    "    'P11': 100, # 40 to get whole tree \n",
    "    'P12': 70,\n",
    "}\n",
    "\n",
    "mask = volume > thresholds[TREE_NAME]\n",
    "volume = None\n",
    "# VolumeVisualizer(mask, binary=True).visualize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualisation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_addition(base, base_with_addition):\n",
    "    base = (base.copy() > 0).astype(np.uint8)\n",
    "    addition = (base_with_addition > 0).astype(np.uint8)\n",
    "    addition[base == 1] = 0\n",
    "    ColorMapVisualizer(base + addition * 4).visualize()\n",
    "    \n",
    "def visualize_lsd(lsd_mask):\n",
    "    ColorMapVisualizer(lsd_mask.astype(np.uint8)).visualize()\n",
    "    \n",
    "def visualize_gradient(lsd_mask):\n",
    "    ColorMapVisualizer(lsd_mask.astype(np.uint8)).visualize(gradient=True)\n",
    "    \n",
    "def visualize_mask_bin(mask):\n",
    "    VolumeVisualizer((mask > 0).astype(np.uint8), binary=True).visualize()\n",
    "    \n",
    "def visualize_mask_non_bin(mask):\n",
    "    VolumeVisualizer((mask > 0).astype(np.uint8) * 255, binary=False).visualize()\n",
    "    \n",
    "def visualize_skeleton(mask, visualize_mask=True, visualize_both_versions=False):\n",
    "    skeleton = skeletonize((mask > 0).astype(np.uint8))\n",
    "    if not visualize_mask or visualize_both_versions:\n",
    "        VolumeVisualizer(skeleton, binary=True).visualize()\n",
    "    if visualize_mask or visualize_both_versions:\n",
    "        skeleton = skeleton.astype(np.uint8) * 4\n",
    "        mask = (mask > 0).astype(np.uint8) * 3\n",
    "        mask[skeleton != 0] = 0\n",
    "        ColorMapVisualizer(skeleton + mask).visualize()\n",
    "\n",
    "def visualize_ultimate(lsd, base_mask):\n",
    "    visualize_lsd(lsd)\n",
    "    visualize_mask_non_bin(lsd)\n",
    "    visualize_addition(base_mask, lsd)\n",
    "    visualize_skeleton(lsd, visualize_mask=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolution utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spherical_kernel(outer_radius, thickness=1, filled=True):    \n",
    "    outer_sphere = morphology.ball(radius=outer_radius)\n",
    "    if filled:\n",
    "        return outer_sphere\n",
    "    \n",
    "    thickness = min(thickness, outer_radius)\n",
    "    \n",
    "    inner_radius = outer_radius - thickness\n",
    "    inner_sphere = morphology.ball(radius=inner_radius)\n",
    "    \n",
    "    begin = outer_radius - inner_radius\n",
    "    end = begin + inner_sphere.shape[0]\n",
    "    outer_sphere[begin:end, begin:end, begin:end] -= inner_sphere\n",
    "    return outer_sphere\n",
    "\n",
    "def convolve_with_ball(img, ball_radius, dtype=np.uint16, normalize=True):\n",
    "    kernel = spherical_kernel(ball_radius, filled=True)\n",
    "    convolved = signal.convolve(img.astype(dtype), kernel.astype(dtype), mode='same')\n",
    "    \n",
    "    if not normalize:\n",
    "        return convolved\n",
    "    \n",
    "    return (convolved / kernel.sum()).astype(np.float16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main region extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_main_regions(binary_mask, min_size=10_000, connectivity=3):\n",
    "    labeled = measure.label(binary_mask, connectivity=connectivity)\n",
    "    region_props = measure.regionprops(labeled)\n",
    "    \n",
    "    main_regions_masks = []\n",
    "    regions_labels = []\n",
    "    bounding_boxes = []\n",
    "    \n",
    "    for props in region_props:\n",
    "        if props.area >= min_size:\n",
    "            main_regions_masks.append(props.filled_image)\n",
    "            regions_labels.append(props.label)\n",
    "            bounding_boxes.append(props.bbox)\n",
    "            \n",
    "    return main_regions_masks, regions_labels, bounding_boxes\n",
    "\n",
    "#TODO add merging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of main regions: 1\n"
     ]
    }
   ],
   "source": [
    "main_regions = get_main_regions(mask)\n",
    "print('number of main regions:', len(main_regions[0])) #TODO merge main regions if more than 1\n",
    "mask_main = main_regions[0][0].astype(np.uint8)\n",
    "\n",
    "VolumeVisualizer(mask_main, binary=True).visualize()\n",
    "# VolumeVisualizer(skeletonize_3d(mask_main.astype(np.uint8)), binary=True).visualize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reconstruction by filling holes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def annihilate_jemiolas(mask, kernel_sizes=[10, 9, 8], fill_threshold=0.5, iters=1, conv_dtype=np.uint16):\n",
    "    kernel_sizes_maps = []\n",
    "    mask = mask.astype(np.uint8)\n",
    "    \n",
    "    for i in range(iters):\n",
    "        kernel_size_map = np.zeros(mask.shape, dtype=np.uint8)\n",
    "\n",
    "        for kernel_size in kernel_sizes:\n",
    "            fill_percentage = convolve_with_ball(mask, kernel_size, dtype=conv_dtype, normalize=True)\n",
    "            \n",
    "            above_threshold_fill_indices = fill_percentage > fill_threshold\n",
    "            kernel_size_map[above_threshold_fill_indices] = kernel_size + 1\n",
    "\n",
    "            mask[above_threshold_fill_indices] = 1\n",
    "            \n",
    "            print(f'Iteration {i + 1} kernel {kernel_size} done')\n",
    "\n",
    "        kernel_sizes_maps.append(kernel_size_map)\n",
    "        print(f'Iteration {i + 1} ended successfully')\n",
    "\n",
    "    return kernel_sizes_maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# lsd_trees = annihilate_jemiolas(mask_main, kernel_sizes=range(0, 13), iters=3)\n",
    "# np.save(source_dir + TREE_NAME + '/reconstruction', lsd_trees)\n",
    "# ===============================================================================\n",
    "lsd_trees = np.load(source_dir + TREE_NAME + '/reconstruction.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstruction = (lsd_trees[-1] > 0).astype(np.uint8)\n",
    "lsd_trees = None\n",
    "# visualize_mask_bin(reconstruction)\n",
    "visualize_skeleton(reconstruction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Onionization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def onionize(mask, kernel_sizes=[10, 9, 8], fill_threshold=0.8, conv_dtype=np.uint16):\n",
    "\n",
    "    mask = mask.astype(np.uint8)\n",
    "    \n",
    "    kernel_size_map = np.zeros(mask.shape, dtype=np.uint8)\n",
    "\n",
    "    for kernel_size in sorted(kernel_sizes):\n",
    "        fill_percentage = convolve_with_ball(mask, kernel_size, dtype=conv_dtype, normalize=True)\n",
    "        above_threshold_fill_indices = fill_percentage >= fill_threshold\n",
    "        kernel_size_map[above_threshold_fill_indices] = kernel_size + 1\n",
    "        print(f'Kernel {kernel_size} done')\n",
    "\n",
    "    return kernel_size_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kernel 0 done\n",
      "Kernel 1 done\n",
      "Kernel 2 done\n",
      "Kernel 3 done\n",
      "Kernel 4 done\n",
      "Kernel 5 done\n",
      "Kernel 6 done\n",
      "Kernel 7 done\n",
      "Kernel 8 done\n",
      "Kernel 9 done\n",
      "Kernel 10 done\n",
      "Kernel 11 done\n",
      "Kernel 12 done\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './data/P11/onionization'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[1;32m    426\u001b[0m         \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 428\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos_fspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    429\u001b[0m         \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './data/P11/onionization'"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# onion = onionize(reconstruction, kernel_sizes=range(13), fill_threshold=1)\n",
    "# np.save(source_dir + TREE_NAME + '/onionization', onion)\n",
    "# ===============================================================================\n",
    "onion = np.load(source_dir + TREE_NAME + '/onionization.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_lsd(onion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Skeleton fixing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "skeleton = skeletonize_3d(reconstruction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dumb stretching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iters_wrapper(func): \n",
    "    def inner(data, *args, iters=1, **kwargs): \n",
    "        result = func(data, *args, **kwargs)\n",
    "        \n",
    "        for i in range(iters - 1):\n",
    "            result = func(result, *args, **kwargs)\n",
    "            \n",
    "        return result\n",
    "    return inner "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "@iters_wrapper\n",
    "def stretch_skeleton(skeleton, kernel_size_map):\n",
    "    max_radius = int(kernel_size_map.max())\n",
    "    padded_skeleton = np.pad(skeleton, max_radius)\n",
    "    padded_kernel_map = np.pad(kernel_size_map, max_radius)\n",
    "    \n",
    "    skeleton_voxels = np.argwhere(padded_skeleton)\n",
    "    kernels = [spherical_kernel(radius) for radius in range(max_radius)]\n",
    "    \n",
    "    new_skeleton = np.zeros(padded_skeleton.shape)\n",
    "    \n",
    "    for voxel_coords in skeleton_voxels:\n",
    "        x, y, z = tuple(voxel_coords)\n",
    "        kernel_radius = padded_kernel_map[x, y, z] - 1\n",
    "        kernel = kernels[kernel_radius]\n",
    "        \n",
    "        kernel_x, kernel_y, kernel_z = tuple(voxel_coords - kernel_radius)\n",
    "        kernel_diameter = 2 * kernel_radius + 1\n",
    "        kernel_map_slice = padded_kernel_map[\n",
    "            kernel_x:kernel_x + kernel_diameter,\n",
    "            kernel_y:kernel_y + kernel_diameter,\n",
    "            kernel_z:kernel_z + kernel_diameter\n",
    "        ]\n",
    "        \n",
    "        neighbours = kernel_map_slice * kernel\n",
    "        \n",
    "        if neighbours.max() == neighbours[kernel_radius, kernel_radius, kernel_radius]:\n",
    "            target_voxel = (x, y, z)\n",
    "            \n",
    "        else:\n",
    "            local_max_coords = np.argwhere(neighbours == neighbours.max())[0]\n",
    "            dx, dy, dz = tuple(local_max_coords - kernel_radius)\n",
    "            target_voxel = (x + dx, y + dy, z + dz)\n",
    "        \n",
    "        new_skeleton[target_voxel] = 1\n",
    "        \n",
    "    return new_skeleton[max_radius:-max_radius, max_radius:-max_radius, max_radius:-max_radius]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### eating leaves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "@iters_wrapper\n",
    "def trim_skeleton(skeleton):   \n",
    "    padded_skeleton = np.pad(skeleton, 1)\n",
    "    new_skeleton = np.zeros(padded_skeleton.shape)\n",
    "    queue = [tuple(np.argwhere(padded_skeleton)[0])]\n",
    "    new_skeleton[queue[0]] == -1;\n",
    "    \n",
    "    while(len(queue) > 0):\n",
    "        x, y, z = queue.pop(0)\n",
    "        \n",
    "        for dx in [-1, 0, 1]:\n",
    "            for dy in [-1, 0, 1]:\n",
    "                for dz in [-1, 0, 1]:\n",
    "                    if dx == dy == dz == 0:\n",
    "                        continue\n",
    "                    \n",
    "                    neighbour_x = x + dx\n",
    "                    neighbour_y = y + dy\n",
    "                    neighbour_z = z + dz\n",
    "                    if padded_skeleton[neighbour_x, neighbour_y, neighbour_z] == 0:\n",
    "                        continue\n",
    "                        \n",
    "                    if new_skeleton[neighbour_x, neighbour_y, neighbour_z] == 0:\n",
    "                        queue.append((neighbour_x, neighbour_y, neighbour_z))\n",
    "                        new_skeleton[neighbour_x, neighbour_y, neighbour_z] = 2;\n",
    "                        new_skeleton[x, y, z] = 1\n",
    "                        \n",
    "    return (new_skeleton[1:-1, 1:-1, 1:-1] == 1).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## thiccness map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def propagate_thiccness(skeleton, kernel_size_map):\n",
    "    padded_skeleton = np.pad(skeleton, 1)\n",
    "    padded_kernels_map = np.pad(kernel_size_map, 1)\n",
    "    \n",
    "    thiccness_map = np.zeros(padded_kernels_map.shape)\n",
    "    thiccness_map[padded_skeleton > 0] = padded_kernels_map[padded_skeleton > 0]\n",
    "    \n",
    "    queue = list([tuple(coords) for coords in np.argwhere(padded_skeleton)])\n",
    "    while(len(queue) > 0):\n",
    "        x, y, z = queue.pop(0)\n",
    "        thiccness = thiccness_map[x, y, z]\n",
    "        \n",
    "        for dx in [-1, 0, 1]:\n",
    "            for dy in [-1, 0, 1]:\n",
    "                for dz in [-1, 0, 1]:\n",
    "                    neighbour_x = x + dx\n",
    "                    neighbour_y = y + dy\n",
    "                    neighbour_z = z + dz\n",
    "                    if thiccness_map[neighbour_x, neighbour_y, neighbour_z] > 0:\n",
    "                        continue\n",
    "                        \n",
    "                    if padded_kernels_map[neighbour_x, neighbour_y, neighbour_z] == 0:\n",
    "                        continue\n",
    "                        \n",
    "                    thiccness_map[neighbour_x, neighbour_y, neighbour_z] = thiccness\n",
    "                    queue.append((neighbour_x, neighbour_y, neighbour_z))\n",
    "                        \n",
    "    return thiccness_map[1:-1, 1:-1, 1:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 25.7 s, sys: 1.78 s, total: 27.4 s\n",
      "Wall time: 27.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "trimmed_skeleton = trim_skeleton(skeleton, iters=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "ends = (skeleton - trimmed_skeleton) * (onion < 5)\n",
    "trimmed_full = trimmed_skeleton + ends\n",
    "\n",
    "labels = measure.label(trimmed_full)\n",
    "trimmed_ultimate = (labels == 1).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_addition(trimmed_ultimate, skeleton)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 25s, sys: 1.27 s, total: 1min 26s\n",
      "Wall time: 1min 46s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "thicc_map = propagate_thiccness(trimmed_ultimate, onion)\n",
    "visualize_gradient(thicc_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bifurcation detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mark_bifurcation_regions(skeleton, thiccness_map):\n",
    "    \n",
    "    max_kernel_radius = int(thiccness_map.max())\n",
    "    kernels = [spherical_kernel(radius, filled=False, thickness=2) for radius in range(max_kernel_radius)]\n",
    "    \n",
    "    padded_skeleton = np.pad(skeleton, max_kernel_radius)\n",
    "    padded_thiccness_map = np.pad(thiccness_map, max_kernel_radius)\n",
    "    bifurcations_map = np.zeros(padded_skeleton.shape)\n",
    "    \n",
    "    for skeleton_voxel in np.argwhere(padded_skeleton > 0):\n",
    "        x, y, z = tuple(skeleton_voxel)\n",
    "        kernel_radius = padded_thiccness_map[x, y, z] - 1\n",
    "        kernel = kernels[kernel_radius]\n",
    "        \n",
    "        skeleton_slice = padded_skeleton[\n",
    "            x-kernel_radius:x+kernel_radius + 1,\n",
    "            y-kernel_radius:y+kernel_radius + 1,\n",
    "            z-kernel_radius:z+kernel_radius + 1\n",
    "        ]\n",
    "        \n",
    "        intersections = (skeleton_slice > 0) * kernel\n",
    "        labelled_intersections = measure.label(intersections)\n",
    "        \n",
    "        bifurcations_map[x, y, z] = np.max(labelled_intersections)\n",
    "#         if np.sum((map_slice * kernel)) > 2:\n",
    "#             bifurcations_map[x, y, z] = 1\n",
    "            \n",
    "    return bifurcations_map[\n",
    "        max_kernel_radius:-max_kernel_radius,\n",
    "        max_kernel_radius:-max_kernel_radius,\n",
    "        max_kernel_radius:-max_kernel_radius\n",
    "    ]\n",
    "\n",
    "def mark_bifurcation_regions2(skeleton):\n",
    "    \n",
    "    padded_skeleton = np.pad(skeleton, 1)\n",
    "    bifurcations_map = np.zeros(padded_skeleton.shape)\n",
    "    \n",
    "    for skeleton_voxel in np.argwhere(padded_skeleton > 0):\n",
    "        x, y, z = tuple(skeleton_voxel)\n",
    "        kernel_radius = 1\n",
    "        kernel = np.ones((3, 3, 3))\n",
    "        kernel[1, 1, 1] = 0\n",
    "        \n",
    "        skeleton_slice = padded_skeleton[\n",
    "            x-kernel_radius:x+kernel_radius + 1,\n",
    "            y-kernel_radius:y+kernel_radius + 1,\n",
    "            z-kernel_radius:z+kernel_radius + 1\n",
    "        ]\n",
    "        \n",
    "        intersections = (skeleton_slice > 0) * kernel\n",
    "#         labelled_intersections = measure.label(intersections)\n",
    "        \n",
    "        bifurcations_map[x, y, z] = np.sum(intersections)\n",
    "#         if np.sum((map_slice * kernel)) > 2:\n",
    "#             bifurcations_map[x, y, z] = 1\n",
    "            \n",
    "    return bifurcations_map[\n",
    "        1:-1,\n",
    "        1:-1,\n",
    "        1:-1\n",
    "    ]\n",
    "\n",
    "def print_kernels(mask, thiccness_map):\n",
    "    \n",
    "    max_kernel_radius = int(thiccness_map.max())\n",
    "    kernels = [spherical_kernel(radius) for radius in range(max_kernel_radius)]\n",
    "    \n",
    "    padded_mask = np.pad(mask, max_kernel_radius)\n",
    "    padded_thiccness_map = np.pad(thiccness_map, max_kernel_radius)\n",
    "    kernels_image = np.zeros(padded_mask.shape)\n",
    "    \n",
    "    for voxel in np.argwhere(padded_mask > 0):\n",
    "        x, y, z = tuple(voxel)\n",
    "        kernel_radius = int(padded_thiccness_map[x, y, z] - 1)\n",
    "        kernel = kernels[kernel_radius]\n",
    "        \n",
    "        mask_slice = kernels_image[\n",
    "            x-kernel_radius:x+kernel_radius + 1,\n",
    "            y-kernel_radius:y+kernel_radius + 1,\n",
    "            z-kernel_radius:z+kernel_radius + 1\n",
    "        ]\n",
    "        \n",
    "        mask_slice[:] = np.logical_or(mask_slice, kernel)\n",
    "            \n",
    "    return kernels_image[\n",
    "        max_kernel_radius:-max_kernel_radius,\n",
    "        max_kernel_radius:-max_kernel_radius,\n",
    "        max_kernel_radius:-max_kernel_radius\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.03 s, sys: 105 ms, total: 1.14 s\n",
      "Wall time: 1.16 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "bifurcation_map = mark_bifurcation_regions2(trimmed_ultimate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_lsd(reconstruction + (bifurcation_map > 2).astype(np.uint8) * 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "bif_mask = (bifurcation_map > 2).astype(np.uint8)\n",
    "bif_kernels_image = print_kernels(bif_mask, thicc_map)\n",
    "visualize_mask_bin(bif_kernels_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_addition(bif_kernels_image, reconstruction)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
